{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coregistration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDKt-HqjwegU",
        "colab_type": "text"
      },
      "source": [
        "Run this notebook in Google Colab.\n",
        "Parts of the code use GPU so go to Runtime -> Change Runtime type - > GPU. \n",
        "# Initialize:\n",
        "This code will prompt you to give access to your google drive, where all the files should be stored. All the file paths should start with \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wPuL39_kDQU",
        "colab_type": "code",
        "outputId": "b095f266-a13b-487c-95bb-b63c42b171cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "import scipy as sp\n",
        "import scipy.misc\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%matplotlib inline\n",
        "!nvidia-smi\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "from scipy.special import expit\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from scipy.optimize import fmin, fmin_tnc\n",
        "import math\n",
        "from skimage.filters import threshold_minimum, median\n",
        "from skimage.morphology import disk\n",
        "from random import  uniform\n",
        "from os import listdir\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from IPython.display import clear_output\n",
        "def calc_iou(prediction, ground_truth):\n",
        "    n_images = len(prediction)\n",
        "    intersection, union = 0, 0\n",
        "    for i in range(n_images):\n",
        "        intersection += np.logical_and(prediction[i] > 0, ground_truth[i] > 0).astype(np.float32).sum() \n",
        "        union += np.logical_or(prediction[i] > 0, ground_truth[i] > 0).astype(np.float32).sum()\n",
        "    return float(intersection) / union\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
        "                        diffY // 2, diffY - diffY//2))\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "      \n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256)\n",
        "        self.up2 = up(512, 128)\n",
        "        self.up3 = up(256, 64)\n",
        "        self.up4 = up(128, 64)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        "      \n",
        "class AugmentedDataset(Dataset):\n",
        "    def __init__(self, X, transform_X=transforms.ToTensor()):\n",
        "        self.X = X\n",
        "        self.transform_X = transform_X\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        x = self.transform_X(x)\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "   \n",
        "def matchshape(confocal,maldi):\n",
        "    # we assume here confocal has a higher resolution than maldi\n",
        "    # we reduce the resolution of outlines so the alignment works faster\n",
        "    h1, w1 = confocal.shape\n",
        "    h2, w2 = maldi.shape\n",
        "    common_denominator = h1/512\n",
        "    maldi = cv2.resize(maldi, dsize=(int(w2*h1/(h2*common_denominator)),int(h1/common_denominator)), interpolation=cv2.INTER_CUBIC)\n",
        "    confocal = cv2.resize(confocal, dsize=(int(w1/common_denominator),int(h1/common_denominator)), interpolation=cv2.INTER_CUBIC)\n",
        "    maldi_denominator = h1/h2\n",
        "    h1, w1 = confocal.shape\n",
        "    h2, w2 = maldi.shape\n",
        "    output1 = np.zeros((max(h1,h2),max(w1,w2)))\n",
        "    output2 = np.zeros((max(h1, h2), max(w1, w2)))\n",
        "    for i in range(len(output1)):\n",
        "        try:\n",
        "            output1[i][:len(confocal[i])] = confocal[i]\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            output2[i][:len(maldi[i])] = maldi[i]\n",
        "        except:\n",
        "            pass\n",
        "    return output1.astype(np.uint8),output2.astype(np.uint8), maldi_denominator, common_denominator\n",
        "\n",
        "def transform_image(X,theta,shiftX,shiftY,scale): # error - negative scale\n",
        "    (height, width) = X.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((width/2,height/2), np.degrees(theta), 1)\n",
        "    Y = cv2.warpAffine(X, M, (width,height))\n",
        "    Y = cv2.resize(Y, dsize=(int(width*scale),int(height*scale)), interpolation=cv2.INTER_CUBIC)\n",
        "    moveX, moveY = width*(scale-1)/2,height*(scale-1)/2\n",
        "    M = np.float32([[1, 0, shiftX-moveX], [0, 1, shiftY-moveY]])\n",
        "    res = cv2.warpAffine(Y, M, (int(width*scale),int(height*scale)))\n",
        "    res = cv2.warpAffine(Y, M, (width,height))\n",
        "    return res\n",
        "\n",
        "def error_fun2(p,X,Y):\n",
        "    \"\"\"cost function to minimize \"\"\"\n",
        "    if p[3] < 0.01: return X.shape[0]**2\n",
        "    transformed_Y = transform_image(Y,p[0],p[1],p[2],p[3])\n",
        "    out = np.abs(np.subtract(transformed_Y,X))\n",
        "    return np.sum(out)\n",
        "\n",
        " \n",
        "def cut_background(image):\n",
        "  shape = image.shape\n",
        "  top,bottom,left,right = 0,shape[0],0,shape[1]\n",
        "  for i in range(shape[0]):\n",
        "    s = np.sum(image[i,:])\n",
        "    if s >= 1:\n",
        "      bottom = i\n",
        "      if top == 0: top = i\n",
        "  for i in range(shape[1]):\n",
        "    s = np.sum(image[:,i])\n",
        "    if s >= 1:\n",
        "      right = i\n",
        "      if left == 0: left = i   \n",
        "  return image[top:bottom,left:right],[top,bottom,left,right]\n",
        "\n",
        "def pad_zeros(image, scale, gap = 0):\n",
        "  h, w = image.shape[:2]\n",
        "  vertical_zeros = np.zeros((h,int(w*(scale-1)/2)))\n",
        "  if gap == 0:\n",
        "    image = np.concatenate((vertical_zeros,image,vertical_zeros),axis = 1)\n",
        "  else:\n",
        "    image = np.concatenate((vertical_zeros,image,np.zeros((h,int(w*(scale-1)/2)+gap))),axis = 1)\n",
        "  horizontal_zeros = np.zeros((int(h*(scale-1)/2),image.shape[1]))\n",
        "  image = np.concatenate((horizontal_zeros,image,horizontal_zeros),axis = 0)\n",
        "\n",
        "  return image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Tue Oct  8 15:47:16 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sMQoWmxZ5w1",
        "colab_type": "text"
      },
      "source": [
        "Run this next cell to get the confocal image oulines for aligning. \"tensor.pt\" file is provided in the same github folder with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ofkpfq_kUIh",
        "colab_type": "code",
        "outputId": "9b13d3a5-2f31-4f16-e2b3-2018a8a8b827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "source": [
        "# the confocal should be the image of Hoecst nuclei staining exported as \"Item\" from Volocity or a similar software\n",
        "confocal_filename = '/content/drive/My Drive/confocal for segmentation/confocal/DAPI.tif'\n",
        "model_filename = '/content/drive/My Drive/confocal for segmentation/tensor.pt'\n",
        "net = UNet(n_channels=3, n_classes=1).cuda()\n",
        "net.load_state_dict(torch.load(model_filename))\n",
        "confocal = Image.open(confocal_filename)\n",
        "w, h = confocal.size\n",
        "confocal = np.array(confocal)\n",
        "m = 255.0/np.max(confocal)\n",
        "z = np.zeros((h,w))\n",
        "confocal = cv2.merge((z,z,m*confocal))\n",
        "confocal = np.uint8(np.array(confocal))\n",
        "confocal2 = cv2.resize(confocal, dsize=(512,512), interpolation=cv2.INTER_CUBIC)\n",
        "test_dataset = AugmentedDataset([confocal2])\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "Y_pred = []\n",
        "for X_batch in test_dataloader:\n",
        "    Y_pred.append(expit(net(X_batch.cuda()).data.cpu().numpy()) > 0.33)\n",
        "Y_pred = np.concatenate(Y_pred)\n",
        "confocal_outline = Image.fromarray(np.uint8(Y_pred[0, 0, :, :] * 255) , 'L')\n",
        "display(confocal_outline) # uncomment to see the confocal outline created\n",
        "confocal_outline = np.array(confocal_outline.resize((w,h), Image.ANTIALIAS))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAAAAADRE4smAAASzUlEQVR4nO2d23rjKgxGYb79/q/M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\nNkCS/wF0cnMEOMG0cwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=512x512 at 0x7FB64714BA58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY5XRA8VauNJ",
        "colab_type": "text"
      },
      "source": [
        "Run this cell if you already have an outline of the confocal image:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yn3l8WPa2xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confocal_outline_path = \"/content/drive/My Drive/confocal for segmentation/outline.png\"\n",
        "confocal_outline = cv2.imread(confocal_outline_path, cv2.IMREAD_GRAYSCALE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kInRvMOrcawJ",
        "colab_type": "text"
      },
      "source": [
        "Run this cell to get an outline of the maldi for the alignment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr3bGcT5aOyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maldi_for_outline = \"/content/drive/My Drive/confocal for segmentation/maldi folder/MALDI__887.553 (1).png\"\n",
        "imMaldi = cv2.imread(maldi_for_outline, cv2.IMREAD_GRAYSCALE)\n",
        "t = threshold_minimum(imMaldi)\n",
        "imMaldi = imMaldi > t\n",
        "maldi_outline = 1-imMaldi.astype(np.uint8)\n",
        "maldi_outline = median(maldi_outline, disk(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDLjrMFIcj93",
        "colab_type": "text"
      },
      "source": [
        "Run this cell if you already have an outline of the maldi:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9x7XR8KcjUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maldi_outline_path = \"/content/drive/My Drive/confocal for segmentation/outline.png\"\n",
        "maldi_outline = cv2.imread(maldi_outline_path, cv2.IMREAD_GRAYSCALE)\n",
        "maldi_outline = maldi_outline/np.max(maldi_outline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4jFbFPWc_oq",
        "colab_type": "text"
      },
      "source": [
        "## Start alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1QKehF-vC-2",
        "colab_type": "code",
        "outputId": "affbde31-5ed0-4854-a414-d68cd205f1df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "h2, w2 = imMaldi.shape # initial maldi dimentions\n",
        "confocal_outline2 = 1-np.array(confocal_outline)/255\n",
        "confocal_outline2, maldi_outline, maldi_denominator, common_denominator = matchshape(confocal_outline2,maldi_outline)\n",
        "h3, w3 = confocal_outline2.shape #common dimentions\n",
        "added_image = cv2.addWeighted(maldi_outline,1,confocal_outline2,1,0)\n",
        "mn = sys.maxsize\n",
        "iterations = 50 # increase for a better alignment, decrease for a faster\n",
        "flag = 0\n",
        "########\n",
        "mn = sys.maxsize\n",
        "for i in range(iterations):\n",
        "  scale = uniform(1,2.5)\n",
        "  p_opt = fmin(error_fun2, [uniform(-0.1, 0.1),uniform(-100, 100),uniform(-100, 100),scale], args=(maldi_outline.astype(np.float64),confocal_outline2.astype(np.float64)),xtol = 1e-13,ftol = 1e-13,disp = 0)\n",
        "  fopt = error_fun2(p_opt,maldi_outline.astype(np.float64),confocal_outline2.astype(np.float64))\n",
        "  if fopt < mn:\n",
        "    mn = fopt\n",
        "    xopt = p_opt\n",
        "  print(\"iteration \"+str(i)+\"/\"+str(2*iterations))\n",
        "for i in range(iterations):\n",
        "  scale = uniform(1,2.5)\n",
        "  p_opt = fmin(error_fun2, [uniform(-0.1, 0.1),uniform(-100, 100),uniform(-100, 100),scale], args=(confocal_outline2.astype(np.float64),maldi_outline.astype(np.float64)),xtol = 1e-13,ftol = 1e-13,disp = 0)\n",
        "  fopt = error_fun2(p_opt,confocal_outline2.astype(np.float64),maldi_outline.astype(np.float64))\n",
        "  if fopt < mn:\n",
        "    mn = fopt\n",
        "    xopt = p_opt\n",
        "    flag = 1\n",
        "  print(\"iteration \"+str(iterations+i)+\"/\"+str(2*iterations))\n",
        "if flag == 1:\n",
        "  maldi = transform_image(maldi_outline,xopt[0],xopt[1],xopt[2],xopt[3])\n",
        "  added_image = cv2.addWeighted(maldi,1,confocal_outline2,1,0)\n",
        "  plt.imshow(added_image, cmap = 'gray')\n",
        "  plt.show()\n",
        "  print(\"Optimal parameters (transform maldi): rotation \",xopt[0],\", X shift \",xopt[1],\",Y shift \",xopt[2],\", scale \",xopt[3]) \n",
        "else:\n",
        "  print(\"Optimal parameters (transform confocal): rotation \",xopt[0],\", X shift \",xopt[1],\",Y shift \",xopt[2],\", scale \",xopt[3]) \n",
        "  maldi = transform_image(maldi_outline,-xopt[0],-xopt[1]/xopt[3],-xopt[2]/xopt[3],1/xopt[3])\n",
        "  added_image = cv2.addWeighted(maldi,1,confocal_outline2,1,0)\n",
        "  plt.imshow(added_image, cmap = 'gray')\n",
        "  plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0/100\n",
            "iteration 1/100\n",
            "iteration 2/100\n",
            "iteration 3/100\n",
            "iteration 4/100\n",
            "iteration 5/100\n",
            "iteration 6/100\n",
            "iteration 7/100\n",
            "iteration 8/100\n",
            "iteration 9/100\n",
            "iteration 10/100\n",
            "iteration 11/100\n",
            "iteration 12/100\n",
            "iteration 13/100\n",
            "iteration 14/100\n",
            "iteration 15/100\n",
            "iteration 16/100\n",
            "iteration 17/100\n",
            "iteration 18/100\n",
            "iteration 19/100\n",
            "iteration 20/100\n",
            "iteration 21/100\n",
            "iteration 22/100\n",
            "iteration 23/100\n",
            "iteration 24/100\n",
            "iteration 25/100\n",
            "iteration 26/100\n",
            "iteration 27/100\n",
            "iteration 28/100\n",
            "iteration 29/100\n",
            "iteration 30/100\n",
            "iteration 31/100\n",
            "iteration 32/100\n",
            "iteration 33/100\n",
            "iteration 34/100\n",
            "iteration 35/100\n",
            "iteration 36/100\n",
            "iteration 37/100\n",
            "iteration 38/100\n",
            "iteration 39/100\n",
            "iteration 40/100\n",
            "iteration 41/100\n",
            "iteration 42/100\n",
            "iteration 43/100\n",
            "iteration 44/100\n",
            "iteration 45/100\n",
            "iteration 46/100\n",
            "iteration 47/100\n",
            "iteration 48/100\n",
            "iteration 49/100\n",
            "iteration 50/100\n",
            "iteration 51/100\n",
            "iteration 52/100\n",
            "iteration 53/100\n",
            "iteration 54/100\n",
            "iteration 55/100\n",
            "iteration 56/100\n",
            "iteration 57/100\n",
            "iteration 58/100\n",
            "iteration 59/100\n",
            "iteration 60/100\n",
            "iteration 61/100\n",
            "iteration 62/100\n",
            "iteration 63/100\n",
            "iteration 64/100\n",
            "iteration 65/100\n",
            "iteration 66/100\n",
            "iteration 67/100\n",
            "iteration 68/100\n",
            "iteration 69/100\n",
            "iteration 70/100\n",
            "iteration 71/100\n",
            "iteration 72/100\n",
            "iteration 73/100\n",
            "iteration 74/100\n",
            "iteration 75/100\n",
            "iteration 76/100\n",
            "iteration 77/100\n",
            "iteration 78/100\n",
            "iteration 79/100\n",
            "iteration 80/100\n",
            "iteration 81/100\n",
            "iteration 82/100\n",
            "iteration 83/100\n",
            "iteration 84/100\n",
            "iteration 85/100\n",
            "iteration 86/100\n",
            "iteration 87/100\n",
            "iteration 88/100\n",
            "iteration 89/100\n",
            "iteration 90/100\n",
            "iteration 91/100\n",
            "iteration 92/100\n",
            "iteration 93/100\n",
            "iteration 94/100\n",
            "iteration 95/100\n",
            "iteration 96/100\n",
            "iteration 97/100\n",
            "iteration 98/100\n",
            "iteration 99/100\n",
            "Optimal parameters (transform confocal): rotation  0.02922613453006509 , X shift  -71.5277939416311 ,Y shift  -50.15012140920133 , scale  1.825218056322687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAAD8CAYAAAB0BUiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIRJCghUiISRYIRJCghUiISRYIRLi/wEikH456LRo7QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAVmiIgTobEt",
        "colab_type": "text"
      },
      "source": [
        "If you already have your alignment parameters input them at the cell below and run it. Flag = 1 means your parameters are for a MALDI transformation, flag = 0 for a confocal image transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW1UA8a7obcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flag = 1\n",
        "xopt = [0,0,0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z_D5sHZpQnD",
        "colab_type": "text"
      },
      "source": [
        "## Crop and save the aligned images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_1Ac-164FFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file locations\n",
        "maldi_folder_path = \"/content/drive/My Drive/confocal for segmentation/maldi folder\"\n",
        "confocal_folder_path = \"/content/drive/My Drive/confocal for segmentation/confocal\"\n",
        "maldi_output_path = \"/content/drive/My Drive/confocal for segmentation/maldi aligned\"\n",
        "crop_confocal_path = \"/content/drive/My Drive/confocal for segmentation/cropped_confocal\"\n",
        "#####################################################################################\n",
        "if not os.path.exists(maldi_output_path):os.mkdir(maldi_output_path)\n",
        "l = os.listdir(maldi_folder_path)\n",
        "l2 = os.listdir(confocal_folder_path)\n",
        "if not os.path.exists(crop_confocal_path):os.mkdir(crop_confocal_path)\n",
        "\n",
        "w_conf = int(w/common_denominator)\n",
        "w_maldi = int(w2*maldi_denominator/common_denominator) \n",
        "\n",
        "if flag == 0: # means confocal was scaled up, image1 = confocal\n",
        "  if w3 > w_conf: # image2 (maldi) is wider, image1 has a black gap on the right\n",
        "    image2_outlines = np.ones((h3,w3))\n",
        "    image2_outlines_transformed = transform_image(image2_outlines,-1*xopt[0],-1*xopt[1]/xopt[3],-1*xopt[2]/xopt[3],1/xopt[3]) # here all the xopt were done for confocal, xopt[3]>1, but here we scale maldi down, so we reverse xopt\n",
        "    _, [top,bottom,left,right] = cut_background(image2_outlines_transformed)\n",
        "    if right > w_conf:\n",
        "      right = w_conf # confocal and maldi are going to be cropped right with [top:bottom,left:right] \n",
        "  elif w3 == w_conf: # image1 (confocal) is wider, image2 has a black gap on the right\n",
        "    image2_outlines = np.concatenate((np.ones((h3,w_maldi)),np.zeros((h3,w3-w_maldi))), axis=1)\n",
        "    image2_outlines_transformed = transform_image(image2_outlines,-1*xopt[0],-1*xopt[1]/xopt[3],-1*xopt[2]/xopt[3],1/xopt[3]) \n",
        "    _, [top,bottom,left,right] = cut_background(image2_outlines_transformed)\n",
        "  for name in l2:\n",
        "    confocal = cv2.imread(confocal_folder_path+\"/\"+name)\n",
        "    cropped_confocal = np.array(confocal)[int(common_denominator*top):int(bottom*common_denominator),int(common_denominator*left):int(right*common_denominator)]\n",
        "    cv2.imwrite(crop_confocal_path+\"/\"+name,cropped_confocal)\n",
        "\n",
        "  for name in l: # make sure you have only maldi images of the same run in the folder, no technical files like \".Thumbs\" etc\n",
        "    im = cv2.imread(maldi_folder_path+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
        "    _, im, _, _ = matchshape(confocal_outline2,im)\n",
        "    im = transform_image(im,-1*xopt[0],-1*xopt[1]/xopt[3],-1*xopt[2]/xopt[3],1/xopt[3])\n",
        "    im = im[top:bottom,left:right]\n",
        "    im = cv2.resize(im, dsize=(cropped_confocal.shape[1],cropped_confocal.shape[0]), interpolation=cv2.INTER_CUBIC)     \n",
        "    cv2.imwrite(maldi_output_path+\"/\"+name,im)\n",
        "else: # means maldi was scaled up, image1 = maldi\n",
        "  if w3 > w_maldi: # image2 (confocal) is wider, image1 has a black gap on the right\n",
        "    image2_outlines = np.ones((h3,w3))\n",
        "    image2_outlines_transformed = transform_image(image2_outlines,0,-1*xopt[1]/xopt[3],-1*xopt[2]/xopt[3],1/xopt[3]) # here all the xopt were done for maldi, xopt[3]>1, but we pretend we scaled confocal down, so we reverse xopt \n",
        "    _, [top,bottom,left,right] = cut_background(image2_outlines_transformed)\n",
        "    if right > w_maldi:\n",
        "      right = w_maldi\n",
        "    gap = 0\n",
        "  elif w3 == w_maldi: # image1 (maldi) is wider, image2 has a black gap on the right\n",
        "    image2_outlines = np.concatenate((np.ones((h3,w_conf)),np.zeros((h3,w3-w_conf))), axis=1)\n",
        "    image2_outlines_transformed = transform_image(image2_outlines,0,-1*xopt[1]/xopt[3],-1*xopt[2]/xopt[3],1/xopt[3]) \n",
        "    plt.imshow(image2_outlines_transformed)\n",
        "    plt.show()\n",
        "    im, [top,bottom,left,right] = cut_background(image2_outlines_transformed)\n",
        "    gap = int((w3-w_conf)*common_denominator)\n",
        "  for name in l2:\n",
        "    confocal = cv2.imread(confocal_folder_path+\"/\"+name)  \n",
        "    new_confocal = pad_zeros(np.array(confocal),xopt[3],gap = gap)\n",
        "    new_confocal_transformed = transform_image(new_confocal,0,-common_denominator*xopt[1],-common_denominator*xopt[2],1)\n",
        "    multiplier = new_confocal_transformed.shape[0]/image2_outlines_transformed.shape[0]\n",
        "    cropped_confocal = new_confocal_transformed[int(top*multiplier):int(bottom*multiplier),int(left*multiplier):int(right*multiplier)] \n",
        "    cv2.imwrite(crop_confocal_path+\"/\"+name,cropped_confocal)\n",
        "\n",
        "  for name in l: # make sure you have only maldi images of the same run in the folder, no technical files like \".Thumbs\" etc\n",
        "    im = cv2.imread(maldi_folder_path+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
        "    _, im, _, _ = matchshape(confocal_outline2,im)\n",
        "    im = transform_image(im,xopt[0],0,0,1)\n",
        "    im = im[top:bottom,left:right]\n",
        "    im = cv2.resize(im, dsize=(cropped_confocal.shape[1],cropped_confocal.shape[0]), interpolation=cv2.INTER_CUBIC)     \n",
        "    cv2.imwrite(maldi_output_path+\"/\"+name,im)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}